<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>CV on 码力全开</title><link>https://zhuzhulang.github.io/blog/categories/cv/</link><description>Recent content in CV on 码力全开</description><generator>Hugo</generator><language>zh-cn</language><copyright>✨ 原创不易，转载请注明作者和链接哦~</copyright><lastBuildDate>Sat, 08 Nov 2025 16:12:49 +0800</lastBuildDate><atom:link href="https://zhuzhulang.github.io/blog/categories/cv/index.xml" rel="self" type="application/rss+xml"/><item><title>YOLO性别与年龄估计</title><link>https://zhuzhulang.github.io/blog/posts/use-yolo-for-humman-age-and-gender-estimiation/</link><pubDate>Sat, 08 Nov 2025 11:39:17 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/use-yolo-for-humman-age-and-gender-estimiation/</guid><description>如何使用YOLO模型进行性别和年龄估计</description></item><item><title>在RK3588主板上使用Docker进行推理</title><link>https://zhuzhulang.github.io/blog/posts/how-to-use-rk3588-npu-in-docker/</link><pubDate>Thu, 23 Oct 2025 21:19:25 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-use-rk3588-npu-in-docker/</guid><description>如何在Docker中调用主板上的NPU</description></item><item><title>视频插帧方案简述</title><link>https://zhuzhulang.github.io/blog/posts/something-about-interpolate-frame/</link><pubDate>Sun, 21 Sep 2025 16:34:01 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/something-about-interpolate-frame/</guid><description>关于视频插帧的一些常用方法</description></item><item><title>YOLO添加注意力机制</title><link>https://zhuzhulang.github.io/blog/posts/add-attention-module-in-yolo/</link><pubDate>Sun, 14 Sep 2025 21:16:01 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/add-attention-module-in-yolo/</guid><description>如何为YOLO添加注意力机制</description></item><item><title>YOLOv11网络结构简述</title><link>https://zhuzhulang.github.io/blog/posts/yolov11-architecture-introduction/</link><pubDate>Sun, 07 Sep 2025 09:49:18 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/yolov11-architecture-introduction/</guid><description>对YOLO11网络结构进行简单的介绍</description></item><item><title>YOLO物体跟踪</title><link>https://zhuzhulang.github.io/blog/posts/how-to-track-object-in-yolo/</link><pubDate>Sat, 06 Sep 2025 09:35:32 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-track-object-in-yolo/</guid><description>如何在YOLO中进行物体跟踪,特别是使用onnxruntime</description></item><item><title>使用YOLO-obb检测旋转物体</title><link>https://zhuzhulang.github.io/blog/posts/how-to-use-yolo-obb-for-rotate-object/</link><pubDate>Thu, 03 Jul 2025 21:19:34 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-use-yolo-obb-for-rotate-object/</guid><description>如何使用YOLO模型检测旋转的物体</description></item><item><title>YOLO + DeepSort 解决目标追踪问题</title><link>https://zhuzhulang.github.io/blog/posts/how-to-use-deepsort-track-object/</link><pubDate>Tue, 01 Jul 2025 16:56:43 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-use-deepsort-track-object/</guid><description>通过使用YOLOv5与DeepSort算法解决一般的目标追踪问题</description></item><item><title>YOLOv5训练自定义数据集</title><link>https://zhuzhulang.github.io/blog/posts/how-to-train-custom-dataset-in-yolov5/</link><pubDate>Sun, 29 Jun 2025 22:03:31 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-train-custom-dataset-in-yolov5/</guid><description>如何通过YOLOv5对自定义数据集进行训练,完成项目中一些实战的工作</description></item><item><title>YOLO数据集格式简述</title><link>https://zhuzhulang.github.io/blog/posts/yolo-dataset-format/</link><pubDate>Sat, 28 Jun 2025 16:21:52 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/yolo-dataset-format/</guid><description>对YOLO数据集格式进行简单的介绍,说明其计算过程</description></item><item><title>YOLOv5目标检测代码精解</title><link>https://zhuzhulang.github.io/blog/posts/in-depth-code-explaination-of-yolov5/</link><pubDate>Fri, 27 Jun 2025 16:29:48 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/in-depth-code-explaination-of-yolov5/</guid><description>手把手从YOLOv3代码入手,为你详细讲解其训练整个实现过程</description></item><item><title>YOLOv3目标检测代码精解</title><link>https://zhuzhulang.github.io/blog/posts/in-depth-code-explaination-of-yolov3/</link><pubDate>Fri, 27 Jun 2025 10:26:11 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/in-depth-code-explaination-of-yolov3/</guid><description>手把手从YOLOv3代码入手,为你详细讲解其推理整个实现过程</description></item><item><title>从"一眼万年"到"万物可识"：YOLO系列目标检测技术的进化之路</title><link>https://zhuzhulang.github.io/blog/posts/unfolding-the-evolution-of-yolo-series-in-object-detection/</link><pubDate>Wed, 25 Jun 2025 09:07:10 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/unfolding-the-evolution-of-yolo-series-in-object-detection/</guid><description>对YOLO整个系列进行简单的介绍</description></item><item><title>从UNet到DeepLab:语义分割网络的架构演进与技术突破</title><link>https://zhuzhulang.github.io/blog/posts/from-unet-to-deeplab/</link><pubDate>Fri, 20 Jun 2025 10:58:39 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/from-unet-to-deeplab/</guid><description>如何通过UNet和DeepLab网络架构的演进逐步解决语义分割中出现的问题</description></item></channel></rss>