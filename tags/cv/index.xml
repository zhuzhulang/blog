<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>CV on 码力全开</title><link>https://zhuzhulang.github.io/blog/tags/cv/</link><description>Recent content in CV on 码力全开</description><generator>Hugo</generator><language>zh-cn</language><copyright>✨ 原创不易，转载请注明作者和链接哦~</copyright><lastBuildDate>Sun, 04 Jan 2026 16:33:17 +0800</lastBuildDate><atom:link href="https://zhuzhulang.github.io/blog/tags/cv/index.xml" rel="self" type="application/rss+xml"/><item><title>基于YOLO的车速检测</title><link>https://zhuzhulang.github.io/blog/posts/yolo-speed-estimate/</link><pubDate>Sun, 04 Jan 2026 16:07:46 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/yolo-speed-estimate/</guid><description>&lt;p>这里来看一个实例,基于YOLO实现对高速公路的车速检测。&lt;/p>
&lt;p>整个过程可以说非常简单,主要用到YOLO、ByteTrack及OpenCV。通过ByteTrack进行车辆目标跟踪,从而方便获取其位置信息。&lt;/p>
&lt;p>要实现车速计算,最简单的方法自然是根据识别框的像素位置进行估计,但是这种方式存在一种问题,无法从图像的像素值得到其实际物理的距离。为此,需要通过一种映射关系建立与真实世界的联系。&lt;/p>
&lt;p>在OpenCV中提供了getPerspectiveTransform函数,我们可以将图像中的四边形变换为一个矩形,从而建立其关系。因为龙门架的高度、车道线的距离一般是规定不变的,从而借助这些隐含信息作为参考,得到其真实的距离度量。&lt;/p>
&lt;p>问题在于如何得到图像中的坐标点,假设我们知道其坐标点信息,那么就可以建立联系了,从而解决车速检测的问题。&lt;/p>
&lt;p>最后为了避免车速出现一些异常值,可以对一秒钟内的速度取平均值,这样有助于系统更加稳健。&lt;/p>
&lt;p>最后我们还可以使用YOLO制造热力图,将其进行显示,详情可以参考&lt;a href="https://cloud.tencent.com/developer/article/2493342">使用YOLOv8创建交通热力图&lt;/a>。&lt;/p>
&lt;p>参考文章:&lt;/p>
&lt;blockquote>
&lt;p>&lt;a href="https://cloud.tencent.com/developer/article/2389959?policyId=1004">https://cloud.tencent.com/developer/article/2389959?policyId=1004&lt;/a>&lt;/p>&lt;/blockquote></description></item><item><title>MobileViT简述</title><link>https://zhuzhulang.github.io/blog/posts/mobilevit-introduction/</link><pubDate>Sun, 07 Dec 2025 16:05:33 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/mobilevit-introduction/</guid><description>对MobileViT网络进行简单的介绍</description></item><item><title>YOLO双Backbone架构设计</title><link>https://zhuzhulang.github.io/blog/posts/double-backbone-in-yolo/</link><pubDate>Sun, 07 Dec 2025 10:25:40 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/double-backbone-in-yolo/</guid><description>介绍YOLO中双Backbone架构的相关设计</description></item><item><title>YOLO11中替换Backbone为MobileNetV3-Small</title><link>https://zhuzhulang.github.io/blog/posts/how-to-replace-backbone-to-mobilenetv3-small-in-yolo/</link><pubDate>Thu, 04 Dec 2025 15:37:06 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-replace-backbone-to-mobilenetv3-small-in-yolo/</guid><description>将YOLO 11中的Backbone网络替换为MobileNet V3 Small</description></item><item><title>YOLO11更换Backbone为ShuffleNetV2</title><link>https://zhuzhulang.github.io/blog/posts/how-to-replace-backbone-to-shufflenetv2-in-yolo11/</link><pubDate>Fri, 28 Nov 2025 20:00:51 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-replace-backbone-to-shufflenetv2-in-yolo11/</guid><description>如何替换YOLO11中Backbone为ShuffleNetV2</description></item><item><title>GhostNet网络简述</title><link>https://zhuzhulang.github.io/blog/posts/ghostnet-introduction/</link><pubDate>Thu, 27 Nov 2025 09:31:49 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/ghostnet-introduction/</guid><description>关于GhostNet网络简单的叙述</description></item><item><title>YOLOv5在边缘设备上的优化</title><link>https://zhuzhulang.github.io/blog/posts/yolov5-in-edge-device/</link><pubDate>Sat, 15 Nov 2025 10:22:02 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/yolov5-in-edge-device/</guid><description>如何让YOLOv5可以在边缘设备上较好的运行</description></item><item><title>YOLO性别与年龄估计</title><link>https://zhuzhulang.github.io/blog/posts/use-yolo-for-humman-age-and-gender-estimiation/</link><pubDate>Sat, 08 Nov 2025 11:39:17 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/use-yolo-for-humman-age-and-gender-estimiation/</guid><description>如何使用YOLO模型进行性别和年龄估计</description></item><item><title>在RK3588主板上使用Docker进行推理</title><link>https://zhuzhulang.github.io/blog/posts/how-to-use-rk3588-npu-in-docker/</link><pubDate>Thu, 23 Oct 2025 21:19:25 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-use-rk3588-npu-in-docker/</guid><description>如何在Docker中调用主板上的NPU</description></item><item><title>视频插帧方案简述</title><link>https://zhuzhulang.github.io/blog/posts/something-about-interpolate-frame/</link><pubDate>Sun, 21 Sep 2025 16:34:01 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/something-about-interpolate-frame/</guid><description>关于视频插帧的一些常用方法</description></item><item><title>YOLO添加注意力机制</title><link>https://zhuzhulang.github.io/blog/posts/add-attention-module-in-yolo/</link><pubDate>Sun, 14 Sep 2025 21:16:01 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/add-attention-module-in-yolo/</guid><description>如何为YOLO添加注意力机制</description></item><item><title>YOLOv11网络结构简述</title><link>https://zhuzhulang.github.io/blog/posts/yolov11-architecture-introduction/</link><pubDate>Sun, 07 Sep 2025 09:49:18 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/yolov11-architecture-introduction/</guid><description>对YOLO11网络结构进行简单的介绍</description></item><item><title>YOLO物体跟踪</title><link>https://zhuzhulang.github.io/blog/posts/how-to-track-object-in-yolo/</link><pubDate>Sat, 06 Sep 2025 09:35:32 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-track-object-in-yolo/</guid><description>如何在YOLO中进行物体跟踪,特别是使用onnxruntime</description></item></channel></rss>