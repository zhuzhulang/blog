<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI on 码力全开</title><link>https://zhuzhulang.github.io/blog/tags/ai/</link><description>Recent content in AI on 码力全开</description><generator>Hugo</generator><language>zh-cn</language><copyright>✨ 原创不易，转载请注明作者和链接哦~</copyright><lastBuildDate>Wed, 07 Jan 2026 15:28:19 +0800</lastBuildDate><atom:link href="https://zhuzhulang.github.io/blog/tags/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>卷积神经网络特征提取</title><link>https://zhuzhulang.github.io/blog/posts/convolution-network-introduction/</link><pubDate>Wed, 07 Jan 2026 15:07:01 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/convolution-network-introduction/</guid><description>将介绍卷积神经网络是如何从图像中提取特征</description></item><item><title>自动驾驶与传感器融合</title><link>https://zhuzhulang.github.io/blog/posts/autonomous-driving-sensor-fusion/</link><pubDate>Wed, 07 Jan 2026 09:56:24 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/autonomous-driving-sensor-fusion/</guid><description>对自动驾驶中传感器融合进行简单介绍</description></item><item><title>大模型并行策略简述</title><link>https://zhuzhulang.github.io/blog/posts/parallelism-strategy-introduction/</link><pubDate>Sat, 03 Jan 2026 21:33:07 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/parallelism-strategy-introduction/</guid><description>&lt;p>这里对大模型并行计算中的策略进行简单的介绍,主要涵盖如下一些策略的内容:&lt;/p>
&lt;ul>
&lt;li>数据并行&lt;/li>
&lt;li>模型并行&lt;/li>
&lt;li>张量并行&lt;/li>
&lt;li>流水线并行&lt;/li>
&lt;/ul>
&lt;p>其中数据并行(DP,Data Parallelism)是最简单的,就是将训练的数据集拆分为大小相同的若干份,模型对不同的数据子集进行训练,在各个分组训练完成后需要进行全局的参数同步。&lt;/p>
&lt;p>而张量并行(TP,Tensor Parallelism)通过将模型中的张量(如权重矩阵)按行或列切分到多个计算设备上,以解决单设备内存不足问题并提升大模型训练效率。其属于模型并行中的一种,核心思想是将单个模型层的参数或计算任务拆分到不同设备上执行,如矩阵乘法拆分到不同的GPU上运行。&lt;/p>
&lt;p>模型并行(Model Parallelism)是通过将模型不同的部分分配给多个设备上进行计算,比如将不同的层分配给不同的设备上,但这种朴素策略存在GPU利用率低的问题。与之类似的是流水线并行(PP,Pipeline Parallelism),通过将模型的不同层按顺序分配到不同设备上的方法。&lt;/p>
&lt;p>流水线并行通过将输入数据切分成多个微批次,使得每个设备可以在处理完当前批次后立即处理下一个批次,从而提高设备利用率。主要策略有Gpipe和PipeDream流水线并行。&lt;/p>
&lt;p>参考文章:&lt;/p>
&lt;blockquote>
&lt;p>&lt;a href="https://developer.aliyun.com/article/1257832">https://developer.aliyun.com/article/1257832&lt;/a>
&lt;a href="https://blog.csdn.net/shizheng_Li/article/details/144138542">https://blog.csdn.net/shizheng_Li/article/details/144138542&lt;/a>
&lt;a href="https://blog.csdn.net/m0_59164520/article/details/142731435">https://blog.csdn.net/m0_59164520/article/details/142731435&lt;/a>
&lt;a href="https://www.cnblogs.com/khronos0206/p/18606724">https://www.cnblogs.com/khronos0206/p/18606724&lt;/a>
&lt;a href="https://zhuanlan.zhihu.com/p/613196255">https://zhuanlan.zhihu.com/p/613196255&lt;/a>&lt;/p>&lt;/blockquote></description></item><item><title>Ring算法简述</title><link>https://zhuzhulang.github.io/blog/posts/ring-algorithm-introduction/</link><pubDate>Sat, 03 Jan 2026 16:01:12 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/ring-algorithm-introduction/</guid><description>对分布式并行中Ring算法进行简单的介绍</description></item><item><title>分布式并行通信原语简述</title><link>https://zhuzhulang.github.io/blog/posts/parallel-primitives-introduction/</link><pubDate>Sat, 03 Jan 2026 09:51:41 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/parallel-primitives-introduction/</guid><description>对大模型分布式并行中各种通信原语进行简单的介绍</description></item><item><title>Switch Transformer简介</title><link>https://zhuzhulang.github.io/blog/posts/switch-transformer-introduction/</link><pubDate>Fri, 02 Jan 2026 21:48:29 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/switch-transformer-introduction/</guid><description>对Switch Transformer进行简单的介绍</description></item><item><title>Transformer各类位置编码技术简述</title><link>https://zhuzhulang.github.io/blog/posts/transformer-position-encoder-introduction/</link><pubDate>Wed, 31 Dec 2025 15:24:15 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/transformer-position-encoder-introduction/</guid><description>对Transformer各类位置编码技术进行简单的叙述</description></item><item><title>MQA与GQA简述</title><link>https://zhuzhulang.github.io/blog/posts/mqa-and-gqa-introduction/</link><pubDate>Wed, 31 Dec 2025 09:44:26 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/mqa-and-gqa-introduction/</guid><description>对MHA、MQA及GQA进行简单的介绍</description></item><item><title>PageAttention简述</title><link>https://zhuzhulang.github.io/blog/posts/pageattention-introduction/</link><pubDate>Tue, 30 Dec 2025 21:07:00 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/pageattention-introduction/</guid><description>关于PageAttention的简单介绍</description></item><item><title>FlashAttention简述</title><link>https://zhuzhulang.github.io/blog/posts/flashattention-introduction/</link><pubDate>Tue, 30 Dec 2025 15:46:57 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/flashattention-introduction/</guid><description>对FlashAttention进行简单的介绍</description></item><item><title>int8量化概述</title><link>https://zhuzhulang.github.io/blog/posts/how-to-int8-quantization/</link><pubDate>Thu, 18 Dec 2025 16:29:26 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-int8-quantization/</guid><description>如何实现int8量化</description></item><item><title>MobileViT简述</title><link>https://zhuzhulang.github.io/blog/posts/mobilevit-introduction/</link><pubDate>Sun, 07 Dec 2025 16:05:33 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/mobilevit-introduction/</guid><description>对MobileViT网络进行简单的介绍</description></item><item><title>YOLO双Backbone架构设计</title><link>https://zhuzhulang.github.io/blog/posts/double-backbone-in-yolo/</link><pubDate>Sun, 07 Dec 2025 10:25:40 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/double-backbone-in-yolo/</guid><description>介绍YOLO中双Backbone架构的相关设计</description></item><item><title>YOLO11中替换Backbone为MobileNetV3-Small</title><link>https://zhuzhulang.github.io/blog/posts/how-to-replace-backbone-to-mobilenetv3-small-in-yolo/</link><pubDate>Thu, 04 Dec 2025 15:37:06 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-replace-backbone-to-mobilenetv3-small-in-yolo/</guid><description>将YOLO 11中的Backbone网络替换为MobileNet V3 Small</description></item><item><title>YOLO11更换Backbone为ShuffleNetV2</title><link>https://zhuzhulang.github.io/blog/posts/how-to-replace-backbone-to-shufflenetv2-in-yolo11/</link><pubDate>Fri, 28 Nov 2025 20:00:51 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-replace-backbone-to-shufflenetv2-in-yolo11/</guid><description>如何替换YOLO11中Backbone为ShuffleNetV2</description></item><item><title>GhostNet网络简述</title><link>https://zhuzhulang.github.io/blog/posts/ghostnet-introduction/</link><pubDate>Thu, 27 Nov 2025 09:31:49 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/ghostnet-introduction/</guid><description>关于GhostNet网络简单的叙述</description></item><item><title>YOLOv5在边缘设备上的优化</title><link>https://zhuzhulang.github.io/blog/posts/yolov5-in-edge-device/</link><pubDate>Sat, 15 Nov 2025 10:22:02 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/yolov5-in-edge-device/</guid><description>如何让YOLOv5可以在边缘设备上较好的运行</description></item><item><title>YOLO性别与年龄估计</title><link>https://zhuzhulang.github.io/blog/posts/use-yolo-for-humman-age-and-gender-estimiation/</link><pubDate>Sat, 08 Nov 2025 11:39:17 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/use-yolo-for-humman-age-and-gender-estimiation/</guid><description>如何使用YOLO模型进行性别和年龄估计</description></item><item><title>YOLO添加注意力机制</title><link>https://zhuzhulang.github.io/blog/posts/add-attention-module-in-yolo/</link><pubDate>Sun, 14 Sep 2025 21:16:01 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/add-attention-module-in-yolo/</guid><description>如何为YOLO添加注意力机制</description></item><item><title>YOLOv11网络结构简述</title><link>https://zhuzhulang.github.io/blog/posts/yolov11-architecture-introduction/</link><pubDate>Sun, 07 Sep 2025 09:49:18 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/yolov11-architecture-introduction/</guid><description>对YOLO11网络结构进行简单的介绍</description></item><item><title>YOLO物体跟踪</title><link>https://zhuzhulang.github.io/blog/posts/how-to-track-object-in-yolo/</link><pubDate>Sat, 06 Sep 2025 09:35:32 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-track-object-in-yolo/</guid><description>如何在YOLO中进行物体跟踪,特别是使用onnxruntime</description></item><item><title>MoE简述</title><link>https://zhuzhulang.github.io/blog/posts/introduction-of-moe/</link><pubDate>Fri, 15 Aug 2025 08:57:51 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/introduction-of-moe/</guid><description>关于大模型中MoE的简单学习</description></item><item><title>PyTorch分布式数据并行入门</title><link>https://zhuzhulang.github.io/blog/posts/pytorch-distributed-data-parallel/</link><pubDate>Mon, 04 Aug 2025 10:45:50 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/pytorch-distributed-data-parallel/</guid><description>如何使用DDP实现分布式数据并行训练</description></item><item><title>预训练大模型内存占用估计</title><link>https://zhuzhulang.github.io/blog/posts/how-to-compute-pretrained-model-parameter-and-memory-usage/</link><pubDate>Tue, 22 Jul 2025 08:30:57 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-compute-pretrained-model-parameter-and-memory-usage/</guid><description>如何对预训练大模型训练占用的内存进行估算</description></item><item><title>Transformer模型新解</title><link>https://zhuzhulang.github.io/blog/posts/a-new-perspective-of-transformer/</link><pubDate>Tue, 15 Jul 2025 22:17:14 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/a-new-perspective-of-transformer/</guid><description>从一种新的视角看Transformer模型</description></item><item><title>使用YOLO-obb检测旋转物体</title><link>https://zhuzhulang.github.io/blog/posts/how-to-use-yolo-obb-for-rotate-object/</link><pubDate>Thu, 03 Jul 2025 21:19:34 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-use-yolo-obb-for-rotate-object/</guid><description>如何使用YOLO模型检测旋转的物体</description></item><item><title>点云图可视化</title><link>https://zhuzhulang.github.io/blog/posts/how-to-visualization-point-cloud/</link><pubDate>Wed, 02 Jul 2025 19:53:38 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-visualization-point-cloud/</guid><description>如何对点云图进行可视化</description></item><item><title>YOLO + DeepSort 解决目标追踪问题</title><link>https://zhuzhulang.github.io/blog/posts/how-to-use-deepsort-track-object/</link><pubDate>Tue, 01 Jul 2025 16:56:43 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-use-deepsort-track-object/</guid><description>通过使用YOLOv5与DeepSort算法解决一般的目标追踪问题</description></item><item><title>YOLOv5训练自定义数据集</title><link>https://zhuzhulang.github.io/blog/posts/how-to-train-custom-dataset-in-yolov5/</link><pubDate>Sun, 29 Jun 2025 22:03:31 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-train-custom-dataset-in-yolov5/</guid><description>如何通过YOLOv5对自定义数据集进行训练,完成项目中一些实战的工作</description></item><item><title>YOLO数据集格式简述</title><link>https://zhuzhulang.github.io/blog/posts/yolo-dataset-format/</link><pubDate>Sat, 28 Jun 2025 16:21:52 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/yolo-dataset-format/</guid><description>对YOLO数据集格式进行简单的介绍,说明其计算过程</description></item><item><title>YOLOv5目标检测代码精解</title><link>https://zhuzhulang.github.io/blog/posts/in-depth-code-explaination-of-yolov5/</link><pubDate>Fri, 27 Jun 2025 16:29:48 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/in-depth-code-explaination-of-yolov5/</guid><description>手把手从YOLOv3代码入手,为你详细讲解其训练整个实现过程</description></item><item><title>YOLOv3目标检测代码精解</title><link>https://zhuzhulang.github.io/blog/posts/in-depth-code-explaination-of-yolov3/</link><pubDate>Fri, 27 Jun 2025 10:26:11 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/in-depth-code-explaination-of-yolov3/</guid><description>手把手从YOLOv3代码入手,为你详细讲解其推理整个实现过程</description></item><item><title>从"一眼万年"到"万物可识"：YOLO系列目标检测技术的进化之路</title><link>https://zhuzhulang.github.io/blog/posts/unfolding-the-evolution-of-yolo-series-in-object-detection/</link><pubDate>Wed, 25 Jun 2025 09:07:10 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/unfolding-the-evolution-of-yolo-series-in-object-detection/</guid><description>对YOLO整个系列进行简单的介绍</description></item><item><title>从UNet到DeepLab:语义分割网络的架构演进与技术突破</title><link>https://zhuzhulang.github.io/blog/posts/from-unet-to-deeplab/</link><pubDate>Fri, 20 Jun 2025 10:58:39 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/from-unet-to-deeplab/</guid><description>如何通过UNet和DeepLab网络架构的演进逐步解决语义分割中出现的问题</description></item><item><title>PostgreSQL + 向量搜索:解锁关系型数据库的AI潜能</title><link>https://zhuzhulang.github.io/blog/posts/how-to-use-postgresql-as-vector-database/</link><pubDate>Tue, 17 Jun 2025 16:04:15 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-use-postgresql-as-vector-database/</guid><description>如何将PostgreSQL摇身一变为向量数据库,并在项目中进行使用</description></item><item><title>Dify二次开发-新增图表类型</title><link>https://zhuzhulang.github.io/blog/posts/how-to-add-new-chart-in-plugins/</link><pubDate>Mon, 16 Jun 2025 07:20:24 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-add-new-chart-in-plugins/</guid><description>如何根据实际需求新增图表</description></item><item><title>Dify二次开发-生成图表</title><link>https://zhuzhulang.github.io/blog/posts/how-to-use-dify-generate-graph/</link><pubDate>Sun, 15 Jun 2025 15:09:13 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-use-dify-generate-graph/</guid><description>如何在Dify中根据数据库中的数据生成图表</description></item><item><title>Dify二次开发-使用MCP协议查询数据库数据</title><link>https://zhuzhulang.github.io/blog/posts/how-to-use-mcp-protocol-query-data/</link><pubDate>Fri, 13 Jun 2025 20:27:30 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-use-mcp-protocol-query-data/</guid><description>如何通过MCP协议对数据库中数据进行查询</description></item><item><title>Dify二次开发-新增工具</title><link>https://zhuzhulang.github.io/blog/posts/how-to-add-custom-tool/</link><pubDate>Sat, 24 May 2025 22:55:27 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-add-custom-tool/</guid><description>在Dify上新增内置工具</description></item><item><title>Dify二次开发-重置管理员邮箱</title><link>https://zhuzhulang.github.io/blog/posts/how-to-reset-email-in-dify/</link><pubDate>Thu, 22 May 2025 15:16:54 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-reset-email-in-dify/</guid><description>如何重置Dify的管理员邮箱</description></item><item><title>Dify二次开发-新增模型提供商</title><link>https://zhuzhulang.github.io/blog/posts/how-to-add-custom-providers/</link><pubDate>Tue, 20 May 2025 15:16:54 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-add-custom-providers/</guid><description>如何在Dify上新增模型提供商</description></item><item><title>Dify二次开发-环境搭建</title><link>https://zhuzhulang.github.io/blog/posts/how-to-build-dify-environment/</link><pubDate>Sat, 17 May 2025 15:16:54 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-build-dify-environment/</guid><description>如何搭建Dify环境</description></item><item><title>使用FastSpeech2进行语音合成</title><link>https://zhuzhulang.github.io/blog/posts/how-to-use-fastspeech2-for-speech-synthesis/</link><pubDate>Tue, 29 Apr 2025 09:01:47 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-use-fastspeech2-for-speech-synthesis/</guid><description>如何使用FastSpeech2的模型实现中文语音合成</description></item><item><title>使用VITS进行语音合成</title><link>https://zhuzhulang.github.io/blog/posts/how-to-use-vits-for-speech-synthesis/</link><pubDate>Sat, 26 Apr 2025 09:13:13 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-use-vits-for-speech-synthesis/</guid><description>如何使用VITS模型进行中文语音合成</description></item><item><title>使用PaddleOCR进行表格识别</title><link>https://zhuzhulang.github.io/blog/posts/how-to-use-paddleocr-recognition-table/</link><pubDate>Tue, 22 Apr 2025 10:16:54 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-use-paddleocr-recognition-table/</guid><description>将介绍如何通过PaddleOCR实现表格识别的需求</description></item><item><title>使用AI提取歌词</title><link>https://zhuzhulang.github.io/blog/posts/how-to-use-ai-extract-lyrics/</link><pubDate>Wed, 12 Mar 2025 10:16:54 +0800</pubDate><guid>https://zhuzhulang.github.io/blog/posts/how-to-use-ai-extract-lyrics/</guid><description>如何使用AI智能地从网页中提取歌词</description></item></channel></rss>